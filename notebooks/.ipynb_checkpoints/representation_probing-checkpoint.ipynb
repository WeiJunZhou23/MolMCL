{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bb89c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rogi import RoughnessIndex\n",
    "\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import squareform\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy import interpolate\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from collections import defaultdict\n",
    "\n",
    "import yaml\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from molmcl.finetune.loader import MoleculeDataset\n",
    "from molmcl.finetune.model import GNNPredictor\n",
    "\n",
    "from molmcl.splitters import scaffold_split, moleculeace_split\n",
    "from molmcl.utils.draw import draw_mols, draw_mol_with_highlight\n",
    "from molmcl.utils.moleculeace import moleculeace_similarity, get_fc\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from finetune import train as train_func\n",
    "from finetune import eval as eval_func\n",
    "from finetune import get_optimizer, set_seed, optimize_prompt_weight_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a345800-302c-4318-9fc2-37b1774ad0a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../config/moleculeace/chembl.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config['dataset']['data_name'] = 'CHEMBL237_Ki'\n",
    "config['dataset']['data_dir'] = '../data/finetune/moleculeace'\n",
    "config['dataset']['feat_type'] = 'basic'\n",
    "config['optim']['scheduler'] = 'cos_anneal'\n",
    "config['optim']['gradient_clip'] = 5\n",
    "config['optim']['prompt_lr'] = 0.0005\n",
    "config['optim']['pretrain_lr'] = 0.0005\n",
    "config['optim']['finetune_lr'] = 0.0005\n",
    "config['model']['temperature'] = 0.7\n",
    "config['model']['layernorm'] = False\n",
    "config['model']['normalize'] = False\n",
    "config['model']['use_prompt'] = True\n",
    "config['model']['emb_dim'] = 300\n",
    "config['model']['num_layer'] = 5\n",
    "config['model']['checkpoint'] = '../checkpoint/zinc-gnn_basic.pt'\n",
    "config['model']['backbone'] = 'gnn'\n",
    "config['model']['dropout_ratio'] = 0\n",
    "config['model']['attn_dropout_ratio'] = 0\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(config, few_shot_num=10, few_shot_ratio=0, few_shot_cliff=False, seed=42):\n",
    "    dataset = MoleculeDataset(config['dataset']['data_dir'],\n",
    "                              config['dataset']['data_name'],\n",
    "                              config['dataset']['feat_type'])\n",
    "    num_task = dataset.num_task\n",
    "    print('Loading dataset of size {} with {} target.'.format(len(dataset), num_task))\n",
    "\n",
    "    if 'CHEMBL' in config['dataset']['data_name']:    \n",
    "        train_idx, val_idx, test_idx = moleculeace_split(dataset.smiles, dataset.labels, val_size=0.1, test_size=0.1)\n",
    "    else:\n",
    "        train_idx, val_idx, test_idx = scaffold_split(dataset.smiles, frac_valid=0.1, frac_test=0.1, balanced=False)\n",
    "\n",
    "    # full:\n",
    "    full_dataset = Subset(dataset, train_idx + val_idx + test_idx)\n",
    "    full_loader = DataLoader(full_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = \\\n",
    "        Subset(dataset, train_idx), Subset(dataset, val_idx), Subset(dataset, test_idx)\n",
    "\n",
    "    # train:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    # val:\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    # tst:\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # extract train-cliff pairs:\n",
    "    train_smiles = [dataset.smiles[i] for i in train_idx]\n",
    "    train_labels = [dataset.labels[i] for i in train_idx]\n",
    "    sim = moleculeace_similarity(train_smiles)\n",
    "    fc = (get_fc(train_labels, in_log10=True) > 10).astype(int)\n",
    "    cliffs = np.logical_and(sim == 1, fc == 1).astype(int)\n",
    "    cliff_pair_inds = np.argwhere(cliffs)\n",
    "    noncliffs = np.logical_and(sim == 1, fc == 0).astype(int)\n",
    "    noncliff_pair_inds = np.argwhere(noncliffs)    \n",
    "    \n",
    "    # few_shot:\n",
    "    if few_shot_num > 0 or few_shot_ratio > 0:\n",
    "        if few_shot_ratio > 0:\n",
    "            few_shot_num = int(len(train_idx) * few_shot_ratio)\n",
    "            \n",
    "        train_fps = np.array([np.array(get_fp(smi)) for smi in train_smiles])\n",
    "\n",
    "        if few_shot_num < len(train_idx):\n",
    "            kmeans = KMeans(n_clusters=few_shot_num).fit(train_fps)\n",
    "            few_shot_idx = np.argmin(euclidean_distances(train_fps, kmeans.cluster_centers_), axis=0)\n",
    "            few_shot_idx = set(few_shot_idx)\n",
    "            few_shot_idx = [train_idx[i] for i in few_shot_idx]\n",
    "        else:\n",
    "            few_shot_idx = train_idx\n",
    "\n",
    "        few_shot_dataset = Subset(dataset, few_shot_idx)\n",
    "        few_shot_loader = DataLoader(few_shot_dataset, batch_size=len(few_shot_dataset), shuffle=True)\n",
    "    else:\n",
    "        few_shot_loader = None\n",
    "\n",
    "    return {'dataset': dataset,\n",
    "            'splits': [train_idx, val_idx, test_idx],\n",
    "            'mmp_inds': [noncliff_pair_inds, cliff_pair_inds],\n",
    "            'dataloader': [train_loader, val_loader, test_loader, full_loader, few_shot_loader]}\n",
    "\n",
    "def sample_triplet(cliff_pair_inds, noncliff_pair_inds, seed=-1):\n",
    "    if seed > -1:\n",
    "        np.random.seed(seed)\n",
    "    while True:\n",
    "        c_idx = np.random.choice(np.arange(len(cliff_pair_inds)))\n",
    "        c_pair = cliff_pair_inds[c_idx]\n",
    "        nc_idx = np.argwhere(c_pair[0] == noncliff_pair_inds[:, 0])\n",
    "        if len(nc_idx):\n",
    "            nc_idx = np.random.choice(nc_idx.flatten())\n",
    "            nc_pair = noncliff_pair_inds[nc_idx]\n",
    "            break\n",
    "    return c_pair, nc_pair\n",
    "\n",
    "def get_reps_local(ori_model, loader, config, best_checkpoint=None, channel_idx=-1):\n",
    "    model = copy.deepcopy(ori_model)\n",
    "    if best_checkpoint is not None:\n",
    "        model.load_state_dict(best_checkpoint)\n",
    "    \n",
    "    graph_rep_list, label_list, smiles_list = [], [], []\n",
    "    model.eval()\n",
    "    for batch in (loader):\n",
    "        batch.to(config['device'])        \n",
    "        with torch.no_grad():\n",
    "            graph_reps = []\n",
    "            if model.backbone == 'gps':\n",
    "                h_g, node_repres = model.gnn(batch.x, batch.pe, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            else:\n",
    "                h_g, node_repres = model.gnn(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "\n",
    "            # map back to batched nodes for aggregation\n",
    "            batch_x, batch_mask = to_dense_batch(node_repres, batch.batch)\n",
    "\n",
    "            # conditional aggregation given the prompt_inds\n",
    "            for i in range(len(model.prompt_token)):\n",
    "                h_g, h_x, _ = model.aggrs[i](batch_x, batch_mask)\n",
    "                if config['model']['normalize']:\n",
    "                    h_g = F.normalize(h_g, dim=-1)\n",
    "                graph_reps.append(h_g)\n",
    "\n",
    "        graph_rep_list.append(torch.stack(graph_reps))\n",
    "        label_list.append(batch.label.view(-1, model.num_tasks))\n",
    "        smiles_list += batch.smi\n",
    "        \n",
    "    graph_reps = torch.concat(graph_rep_list, dim=1)\n",
    "    if channel_idx == -1:\n",
    "        prompt_weight = model.get_prompt_weight(act=model.act)\n",
    "        graph_rep = torch.matmul(graph_reps.transpose(0, 2), prompt_weight).transpose(0, 1)\n",
    "    else:\n",
    "        graph_rep = graph_reps[channel_idx]\n",
    "    graph_rep = graph_rep.detach().cpu()\n",
    "    \n",
    "    labels = torch.concat(label_list, dim=0).detach().cpu()\n",
    "\n",
    "    return smiles_list, graph_rep, labels\n",
    "\n",
    "get_fp = lambda key: AllChem.GetMorganFingerprintAsBitVect(\n",
    "    Chem.MolFromSmiles(key), radius=2, nBits=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857af2d7",
   "metadata": {},
   "source": [
    "## Visualization (0 $\\to$ 100 epochs):\n",
    "The experiment of representation space probe in Figure 3. \n",
    "\n",
    "For fair comparison, the model in this experiment is trained using the basic feature set (same as MolCLR and GraphLoG), as well as the same pre-training dataset (ZINC), model architecture (GIN) and hyperparameters (num_layer=5, emb_dim=300, ...). \n",
    "\n",
    "To perform the same analysis on MolCLR and GraphLoG, one can download the checkpoint from their github repositories ([MolCLR](https://github.com/yuyangw/MolCLR) and [GraphLoG](https://github.com/DeepGraphLearning/GraphLoG/tree/main)), and only load the checkpoint for GNN module. Make sure to set `use_prompt=False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d8b86-25df-4973-a284-2c8b5e21033c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ri_metric = 'euclidean'  # euclidean, cosine\n",
    "best_initialization = None\n",
    "\n",
    "# Get Dataloader:\n",
    "outputs = get_dataloaders(config, few_shot_num=0, few_shot_ratio=0, few_shot_cliff=False)\n",
    "dataset = outputs['dataset']\n",
    "train_idx, val_idx, test_idx = outputs['splits']\n",
    "noncliff_pair_inds, cliff_pair_inds = outputs['mmp_inds']\n",
    "train_loader, val_loader, test_loader, full_loader, few_shot_loader = outputs['dataloader']\n",
    "print('Number of cliff pairs:', len(cliff_pair_inds))\n",
    "\n",
    "# Build Model and Load Checkpoint:\n",
    "model = GNNPredictor(num_layer=config['model']['num_layer'],\n",
    "                     emb_dim=config['model']['emb_dim'],\n",
    "                     num_tasks=dataset.num_task,\n",
    "                     normalize=config['model']['normalize'],\n",
    "                     atom_feat_dim=None,  # for basic_feature\n",
    "                     bond_feat_dim=None,  # for basic_feature\n",
    "                     drop_ratio=config['model']['dropout_ratio'],\n",
    "                     attn_drop_ratio=config['model']['attn_dropout_ratio'],\n",
    "                     temperature=config['model']['temperature'],\n",
    "                     use_prompt=config['model']['use_prompt'],\n",
    "                     model_head=config['model']['heads'],\n",
    "                     layer_norm_out=config['model']['layernorm'], \n",
    "                     backbone=config['model']['backbone'])\n",
    "\n",
    "if config['model']['checkpoint']:\n",
    "    print('Loading checkpoint from {}'.format(config['model']['checkpoint']))\n",
    "    model.load_state_dict(torch.load(config['model']['checkpoint'])['wrapper'], strict=True)\n",
    "\n",
    "model.freeze_aggr_module()\n",
    "model.to(config['device'])\n",
    "\n",
    "set_seed(24)\n",
    "# Initialize Prompt Weights:\n",
    "if config['model']['use_prompt']:\n",
    "    if best_initialization is None:\n",
    "        best_initialization = \\\n",
    "            optimize_prompt_weight_ri(model, train_loader, None, config, act=model.act)\n",
    "\n",
    "    model.set_prompt_weight(best_initialization.to(config['device']))\n",
    "    initial_prompt_probs = model.get_prompt_weight(model.act).data.cpu()\n",
    "    initial_prompt_weights = model.get_prompt_weight('none').data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60128c45-b090-439a-af9b-5960b4312f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run fine-tuning and retrieve representation:\n",
    "method = 'composite'\n",
    "setting2stats = {}\n",
    "r2_history = []\n",
    "smiles_for_plot, scores_history = [], []\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "optimizer = get_optimizer(model, config['optim'])\n",
    "best_score, best_checkpoint = -float('inf'), None\n",
    "\n",
    "set_seed(42)\n",
    "for ep in range(101):\n",
    "    if ep in [0, 10, 20, 50, 80, 100]:\n",
    "        smiles_list, graph_reps, labels = get_reps_local(model, full_loader, config, best_checkpoint)\n",
    "\n",
    "        setting2stats['{}-{}'.format(method, ep)] = (smiles_list, graph_reps, labels)\n",
    "        \n",
    "        X = graph_reps.numpy()[:len(train_idx)]\n",
    "        Y = labels.numpy()[:, 0][:len(train_idx)]\n",
    "        rogi = RoughnessIndex(Y=Y, X=X, metric=ri_metric, verbose=False)\n",
    "        ri = rogi.compute_index()\n",
    "        print('Roughness Index (ep{}): {}'.format(ep, ri))\n",
    "\n",
    "        for batch in val_loader:\n",
    "            with torch.no_grad():\n",
    "                _, scores = model.get_representations(batch.to(config['device']), return_score=True)\n",
    "            break\n",
    "        scores_history.append(scores)\n",
    "        if not smiles_for_plot:\n",
    "            smiles_for_plot = batch.smi\n",
    "        \n",
    "        if ep == 100:\n",
    "            break\n",
    "\n",
    "    loss, _ = train_func(model, train_loader, criterion, optimizer, None, config)\n",
    "    \n",
    "    train_score = eval_func(model, train_loader, config, metric='r2')\n",
    "    val_score = eval_func(model, val_loader, config, metric='r2')\n",
    "    test_score = eval_func(model, test_loader, config, metric='r2')\n",
    "    r2_history.append((train_score, val_score, test_score))\n",
    "    \n",
    "    if -loss > best_score:\n",
    "        best_score = -loss\n",
    "        best_checkpoint = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    if ep % 10 == 0:\n",
    "        print('[epoch {}] Train R2: {} Val R2: {}'.format(ep, train_score, val_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67730d29-326c-4520-84d8-0ef59e8dca7d",
   "metadata": {},
   "source": [
    "#### Plot the training curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4973ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2), tight_layout=True)\n",
    "cmap = cm.get_cmap(\"Set1\")\n",
    "train_r2 = [t[0] for t in r2_history]\n",
    "val_r2 = [t[1] for t in r2_history]\n",
    "\n",
    "plt.plot(train_r2, color=cmap(0), label='{}-{}'.format(method, 'train'))\n",
    "plt.plot(val_r2, '--', color=cmap(0), label='{}-{}'.format(method, 'val'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5839f-ebf1-4d78-a9b4-b4793f133470",
   "metadata": {},
   "source": [
    "#### Visualization of representation space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3c55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute roughness index\n",
    "perplexity = 25\n",
    "n_clusters = 10\n",
    "cliff_distances_dict = defaultdict(list)\n",
    "tsne_seeds = [[42, 43, 44, 44, 44], [42, 43, 48, 48, 46]]\n",
    "\n",
    "method = 'composite'\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 6))\n",
    "((axt1, axt2, axt3, axt4, axt5), (axv1, axv2, axv3, axv4, axv5)) = axes\n",
    "for ei, ep in enumerate([0, 10, 20, 50, 100]):\n",
    "    ei += 1\n",
    "    key = '{}-{}'.format(method, ep)\n",
    "    print(key)\n",
    "\n",
    "    X = setting2stats[key][1].numpy()\n",
    "    Y = setting2stats[key][2].numpy()\n",
    "    X_train, X_val = X[:len(train_idx)], X[len(train_idx):len(train_idx)+len(val_idx)]\n",
    "    Y_train, Y_val = Y[:len(train_idx)], Y[len(train_idx):len(train_idx)+len(val_idx)]\n",
    "\n",
    "    # 2d-plot:\n",
    "    ## Subplot-1:\n",
    "    \n",
    "    rogi = RoughnessIndex(Y=Y_train, X=X_train, metric=ri_metric, verbose=False)\n",
    "    ri = rogi.compute_index()\n",
    "    print('Roughness Index:', ri)\n",
    "\n",
    "    ### compute fingerprint clustering:\n",
    "    X_smi = setting2stats[key][0][:len(train_idx)]\n",
    "    X_fps = np.array([np.array(get_fp(smi)) for smi in X_smi])\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_fps)\n",
    "    kmeans_label = kmeans.labels_\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_train)\n",
    "    kmeans_label2 = kmeans.labels_\n",
    "\n",
    "    ### dimension reduction:\n",
    "    tsne = TSNE(n_components=2, learning_rate='auto', init='random',\n",
    "                metric='precomputed', random_state=tsne_seeds[0][ei-1], perplexity=perplexity)\n",
    "    X_2d = tsne.fit_transform(squareform(rogi._Dx))\n",
    "\n",
    "    ### main plot:\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "      \n",
    "    scatter1 = eval('axt{}'.format(ei)).scatter(\n",
    "        X_2d[:, 0], X_2d[:, 1], c=rogi._Y, s=40, cmap=cm.get_cmap(\"coolwarm\"), \n",
    "        alpha=0.8, zorder=10, edgecolors='grey', linewidths=0.4)\n",
    "        \n",
    "    for ci in set(kmeans_label):\n",
    "        points = X_2d[kmeans_label == ci]\n",
    "        hull = ConvexHull(points)\n",
    "        x_hull = np.append(points[hull.vertices,0],\n",
    "                           points[hull.vertices,0][0])\n",
    "        y_hull = np.append(points[hull.vertices,1],\n",
    "                           points[hull.vertices,1][0])\n",
    "        # interpolate\n",
    "        dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "        dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "        spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0, per=1)\n",
    "        interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "        interp_x, interp_y = interpolate.splev(interp_d, spline)\n",
    "        # plot shape\n",
    "        eval('axt{}'.format(ei)).fill(interp_x, interp_y, '--', c='lightgrey', \n",
    "                 edgecolor='grey', linewidth=1, alpha=0.3, zorder=9)\n",
    "        \n",
    "    plot_text = 'ROGI: {}\\nRand Index: {}'.format(\n",
    "        round(ri, 3),\n",
    "        round(adjusted_rand_score(kmeans_label2, kmeans_label), 3))  \n",
    "    eval('axt{}'.format(ei)).text(0.03, 0.05, plot_text, fontsize=12,\n",
    "        transform=eval('axt{}'.format(ei)).transAxes, zorder=20,\n",
    "        bbox=dict(facecolor='white', edgecolor='grey', boxstyle='round', alpha=0.7))\n",
    "    eval('axt{}'.format(ei)).tick_params(\n",
    "        left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "    ## Subplot-2:\n",
    "    rogi = RoughnessIndex(Y=Y_val, X=X_val, metric=ri_metric, verbose=False)\n",
    "    ri = rogi.compute_index()\n",
    "    \n",
    "    ### dimension reduction:\n",
    "    tsne = TSNE(n_components=2, learning_rate='auto', init='random',\n",
    "                metric='precomputed', random_state=tsne_seeds[1][ei-1], perplexity=perplexity)\n",
    "    X_2d = tsne.fit_transform(squareform(rogi._Dx))\n",
    "\n",
    "    # find test cliffs:\n",
    "    val_smiles = [dataset.smiles[i] for i in val_idx]\n",
    "    val_labels = [dataset.labels[i] for i in val_idx]\n",
    "    sim = moleculeace_similarity(val_smiles)\n",
    "    fc = (get_fc(val_labels, in_log10=True) > 10).astype(int)\n",
    "    cliffs = np.logical_and(sim == 1, fc == 1).astype(int)\n",
    "    cliff_pair_inds = np.unique(np.argwhere(cliffs), axis=0)\n",
    "    cliff_distances = []\n",
    "    for idx_1, idx_2 in cliff_pair_inds:\n",
    "        cliff_distances.append(squareform(rogi._Dx)[idx_1, idx_2])\n",
    "    noncliffs = np.logical_and(sim == 1, fc == 0).astype(int)\n",
    "    noncliff_pair_inds = np.unique(np.argwhere(noncliffs), axis=0)\n",
    "    noncliff_distances = []\n",
    "    for idx_1, idx_2 in noncliff_pair_inds:\n",
    "        noncliff_distances.append(squareform(rogi._Dx)[idx_1, idx_2])\n",
    "    print('Average cliff pair distance:', np.mean(cliff_distances))\n",
    "    print('Average noncliff pair distance:', np.mean(noncliff_distances))\n",
    "    print('Cliff-noncliff distance ratio:', np.mean(cliff_distances) / np.mean(noncliff_distances))\n",
    "    print('----------')\n",
    "    c_pair, nc_pair = sample_triplet(cliff_pair_inds, noncliff_pair_inds, seed=12)\n",
    "    \n",
    "    # n_clusters = len(set(kmeans_label))\n",
    "    # cmap = cm.get_cmap(\"rainbow_r\", n_clusters)\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "    scatter2 = eval('axv{}'.format(ei)).scatter(X_2d[:, 0], X_2d[:, 1], c=rogi._Y, s=40, \n",
    "                          cmap=cmap, alpha=0.8, zorder=10, edgecolors='grey', linewidths=0.4)\n",
    "    \n",
    "    eval('axv{}'.format(ei)).arrow(X_2d[c_pair[0], 0], X_2d[c_pair[0], 1], \n",
    "              X_2d[c_pair[1], 0]-X_2d[c_pair[0], 0], X_2d[c_pair[1], 1]-X_2d[c_pair[0], 1],\n",
    "              color='red', alpha=0.7, zorder=12, width=0.3, head_width=1.3)\n",
    "    eval('axv{}'.format(ei)).arrow(X_2d[nc_pair[0], 0], X_2d[nc_pair[0], 1], \n",
    "              X_2d[nc_pair[1], 0]-X_2d[nc_pair[0], 0], X_2d[nc_pair[1], 1]-X_2d[nc_pair[0], 1],\n",
    "              color='blue', alpha=0.7, zorder=12, width=0.3, head_width=1.2)\n",
    "    if ep == 0:\n",
    "        r2 = 'N/A'\n",
    "    else:\n",
    "        r2 = round(r2_history[ep-1][1], 3)  \n",
    "    dist_ratio = np.mean(cliff_distances) / np.mean(noncliff_distances)\n",
    "    plot_text = 'R-Squared: {}\\nCliff-noncliff Distance Ratio: {}'.format(r2, round(dist_ratio, 3))\n",
    "    eval('axv{}'.format(ei)).text(0.03, 0.05, plot_text, fontsize=12,\n",
    "        transform=eval('axv{}'.format(ei)).transAxes, zorder=12,\n",
    "        bbox=dict(facecolor='white', edgecolor='grey', boxstyle='round', alpha=0.7))\n",
    "\n",
    "    eval('axv{}'.format(ei)).tick_params(\n",
    "        left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.colorbar(scatter2, ax=axes.ravel().tolist())        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f5668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00108d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8502cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b127b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
